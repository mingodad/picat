FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=58 3 2 
scale_included=1
scale_mean_in=0.105200 0.196360 0.290510 0.082263 0.315233 0.100313 49.789001 0.111343 0.088170 0.241463 0.061977 0.530693 0.092737 0.064067 0.053510 50.199001 0.145050 0.180490 1.680788 0.090963 0.830250 0.122433 0.100683 0.092853 0.549523 0.270033 0.666647 0.128953 0.104087 0.100743 0.066923 0.048800 0.098367 0.049937 0.108730 0.095437 0.135290 0.011283 0.076593 0.071323 0.045680 0.144217 0.050273 0.080073 0.297710 0.194513 0.005453 0.032317 0.038343 0.141880 0.015829 49.211334 49.082001 0.047754 5.087691 53.880333 281.096344 
scale_deviation_in=0.305066 1.210738 0.510874 1.535575 0.697699 0.288923 29.251732 0.426998 0.272905 0.690044 0.204394 0.853337 0.286964 0.370154 0.275354 29.027590 0.438276 0.489341 1.805575 0.467868 1.228376 1.031765 0.336737 0.454298 1.656869 0.925480 3.067643 0.566297 0.640887 0.454601 0.430552 0.333378 0.573828 0.334580 0.578029 0.412017 0.403963 0.212597 0.421989 0.373684 0.372504 0.841292 0.239485 0.685248 0.965293 0.963502 0.075705 0.289067 0.247659 0.298422 0.088539 28.894201 28.943134 0.492319 29.038128 221.175827 576.458679 
scale_new_min_in=-1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 -1.000000 
scale_factor_in=1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 1.000000 
scale_mean_out=0.395000 
scale_deviation_out=0.488851 
scale_new_min_out=-1.000000 
scale_factor_out=1.000000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (58, 3, 5.00000000000000000000e-01) (58, 3, 5.00000000000000000000e-01) (0, 3, 5.00000000000000000000e-01) (3, 5, 5.00000000000000000000e-01) (0, 5, 5.00000000000000000000e-01) 
connections (connected_to_neuron, weight)=(0, -4.60497409105300903320e-01) (1, -7.70401656627655029297e-01) (2, 3.22403967380523681641e-01) (3, 1.28084436035156250000e+03) (4, 2.40205764770507812500e+00) (5, 1.29862093925476074219e+00) (6, 6.28085657954216003418e-02) (7, 8.18215787410736083984e-01) (8, 1.44709825515747070312e+00) (9, 1.60919833183288574219e+00) (10, 2.32158231735229492188e+00) (11, -1.86640858650207519531e+00) (12, -6.33431553840637207031e-01) (13, -1.13184356689453125000e+00) (14, 2.61649608612060546875e+00) (15, -1.05573165416717529297e+00) (16, 1.06686365604400634766e+00) (17, 2.16664600372314453125e+00) (18, 2.93692946434020996094e-01) (19, 4.53550910949707031250e+00) (20, 2.92849421501159667969e+00) (21, 8.31822957843542098999e-03) (22, 4.23985099792480468750e+00) (23, 2.06731224060058593750e+00) (24, -8.96223926544189453125e+00) (25, 1.34055949747562408447e-02) (26, -2.35907459259033203125e+01) (27, 5.79066753387451171875e-01) (28, -2.48429931640625000000e+02) (29, 3.66527080535888671875e-01) (30, -1.55106008052825927734e+00) (31, -3.45285654067993164062e+00) (32, 2.38125044852495193481e-02) (33, -1.03035397827625274658e-01) (34, -4.21755504608154296875e+00) (35, -5.15247404575347900391e-01) (36, -2.30986982583999633789e-01) (37, -7.91426360607147216797e-01) (38, 1.39720380306243896484e-01) (39, -1.07934439182281494141e+00) (40, -1.04541114807128906250e+02) (41, -5.99403190612792968750e+00) (42, -2.34935355186462402344e+00) (43, -2.45002341270446777344e+00) (44, -3.22344923019409179688e+00) (45, -4.22212524414062500000e+01) (46, -3.45153236389160156250e+00) (47, -6.55959427356719970703e-01) (48, -5.24743616580963134766e-01) (49, -1.87306940555572509766e+00) (50, -4.91631180047988891602e-02) (51, 2.67261490225791931152e-02) (52, 3.82711708545684814453e-01) (53, 3.12979269027709960938e+00) (54, 1.69040756225585937500e+01) (55, 1.53292119503021240234e-01) (56, -1.31078094244003295898e-01) (57, -6.25650286674499511719e-01) (0, -2.28927358984947204590e-01) (1, -1.63068607449531555176e-01) (2, 2.24350783973932266235e-02) (3, 3.47741165161132812500e+01) (4, 1.93048322200775146484e+00) (5, -1.92982465028762817383e-01) (6, -2.02835947275161743164e-01) (7, 1.31945538520812988281e+00) (8, 3.08134436607360839844e-01) (9, -9.30321037769317626953e-01) (10, -6.85812532901763916016e-01) (11, -1.01321972906589508057e-01) (12, -2.43038192391395568848e-01) (13, 8.36494266986846923828e-02) (14, 4.72977447509765625000e+00) (15, 3.60789187252521514893e-02) (16, 2.46753430366516113281e+00) (17, -8.87925863265991210938e-01) (18, 2.27306202054023742676e-01) (19, 1.42864859104156494141e+00) (20, -3.31451147794723510742e-01) (21, -2.30377390980720520020e-01) (22, 2.50763463973999023438e+00) (23, 1.34903812408447265625e+00) (24, -8.27097892761230468750e+00) (25, -7.75589227676391601562e+00) (26, -3.81908683776855468750e+01) (27, 1.26810526847839355469e+00) (28, -5.41642904281616210938e+00) (29, -7.33538746833801269531e-01) (30, -7.94971084594726562500e+00) (31, -9.66197371482849121094e-01) (32, -1.22379577159881591797e+00) (33, 6.87918543815612792969e-01) (34, -1.89048898220062255859e+00) (35, 1.10572707653045654297e+00) (36, -2.85551637411117553711e-01) (37, -2.85103827714920043945e-01) (38, -9.18279945850372314453e-01) (39, -3.39605718851089477539e-01) (40, -6.62412500381469726562e+00) (41, -3.44292259216308593750e+00) (42, -5.62201380729675292969e-01) (43, -4.50594425201416015625e+00) (44, -5.20181059837341308594e-01) (45, -9.89446759223937988281e-01) (46, 8.68636146187782287598e-02) (47, -8.99139523506164550781e-01) (48, -3.60765278339385986328e-01) (49, 9.78970825672149658203e-02) (50, -1.23878622055053710938e+00) (51, 1.71006973832845687866e-02) (52, -7.54330381751060485840e-02) (53, -6.63885325193405151367e-02) (54, 3.67249336242675781250e+01) (55, -2.89198660850524902344e+00) (56, 7.75789022445678710938e-01) (57, -1.01743993759155273438e+01) (58, 1.49563562870025634766e+00) (59, 1.61202573776245117188e+00) (60, 9.97177362442016601562e-01) 
